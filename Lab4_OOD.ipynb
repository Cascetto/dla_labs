{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e2ac44-45aa-4d2c-9e16-907bf8683659",
   "metadata": {},
   "source": [
    "# Laboratory #4: Adversarial Learning and OOD Detection\n",
    "\n",
    "In this laboratory session we will develop a methodology for detecting OOD samples and measuring the quality of OOD detection. We will also experiment with incorporating adversarial examples during training to render models more robust to adversarial attacks.\n",
    "\n",
    "---\n",
    "## Exercise 1: OOD Detection and Performance Evaluation\n",
    "In this first exercise you will build a simple OOD detection pipeline and implement some performance metrics to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c02677-b193-4c3b-a5e1-c9c4015b9dc2",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Build a simple OOD detection pipeline\n",
    "\n",
    "Implement an OOD detection pipeline (like in the Flipped Activity notebook) using an ID and an OOD dataset of your choice. Some options:\n",
    "\n",
    "+ CIFAR-10 (ID), Subset of CIFAR-100 (OOD). You will need to wrap CIFAR-100 in some way to select a subset of classes that are *not* in CIFAR-10 (see `torch.utils.data.Subset`).\n",
    "+ Labeled Faces in the Wild (ID), CIFAR-10 or FakeData (OOD). The LfW dataset is available in Scikit-learn (see `sklearn.datasets.fetch_lfw_people`).\n",
    "+ Something else, but if using images keep the images reasonably small!\n",
    "\n",
    "In this exercise your *OOD Detector* should produce a score representing how \"out of distribution\" a test sample is. We will implement some metrics in the next exercise, but for now use the techniques from the flipped activity notebook to judge how well OOD scoring is working (i.e. histograms).\n",
    "\n",
    "**Note**: Make sure you make a validation split of your ID dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc06bd79-ac57-473c-9ce0-30c0381ad34f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "from typing import Callable, Optional\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR100, ImageNet\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b3b28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CIFAR100_wrapper(Dataset):\n",
    "\n",
    "    def __init__(self, classes: set[int], get_train: bool = True) -> None:\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        cifar = CIFAR100(\"~/datasets\", download=get_train, train=get_train, transform=ToTensor())\n",
    "        samples = []\n",
    "        labels = []\n",
    "        for i in range(len(cifar)):\n",
    "            if cifar[i][1] in classes:\n",
    "                samples.append(cifar[i][0])\n",
    "                labels.append(torch.Tensor([cifar[i][1]]).long())\n",
    "        self.data = torch.stack(samples)\n",
    "        self.labels = torch.cat(labels)\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]: return self.data[index], self.labels[index]\n",
    "\n",
    "index_id = set(range(20))\n",
    "index_ood = set(range(30, 40))\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "c20 = CIFAR100_wrapper(index_id)\n",
    "c20_train, c20_val = random_split(c20, [0.7, 0.3])\n",
    "c20_test = CIFAR100_wrapper(index_id)\n",
    "c20_ood = CIFAR100_wrapper(index_ood)\n",
    "dl_train = DataLoader(c20_train, batch_size, shuffle=True)\n",
    "dl_val = DataLoader(c20_val, batch_size, shuffle=True)\n",
    "dl_test = DataLoader(c20_test, batch_size, shuffle=True)\n",
    "dl_ood = DataLoader(c20_ood, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72dfd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ood_test(model, dataloader):\n",
    "    max_logits = []\n",
    "    min_logits = []\n",
    "    for x, _ in dataloader:\n",
    "        logits = model(x)\n",
    "        max_logits.append(logits.max(dim=1))\n",
    "        min_logits.append(logits.min(dim=1))\n",
    "    max_logits = torch.vstack(max_logits)\n",
    "    min_logits = torch.vstack(min_logits)\n",
    "    return max_logits - min_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90395410",
   "metadata": {},
   "source": [
    "# Model\n",
    "A simple model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92fcdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, res, input_channels, embedding_channels, n_convs, n_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.input = nn.Sequential(nn.Conv2d(input_channels, embedding_channels, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(3, stride=1))\n",
    "        self.net = nn.Sequential(*[\n",
    "            nn.Sequential(nn.Conv2d(embedding_channels, embedding_channels, kernel_size=3, padding=1), nn.ReLU())\n",
    "        ], nn.MaxPool2d(3, stride=1))\n",
    "        self.head = nn.Linear(((res-4)**2) * embedding_channels, n_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.input(X)\n",
    "        X = self.net(X)\n",
    "        return self.head(X.flatten(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dfc8cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8e576536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution = 32\n",
    "channels = 3\n",
    "embedding_channels = 16\n",
    "n_blocks = 2\n",
    "n_classes = 20\n",
    "model = SimpleCNN(resolution, channels, embedding_channels, n_blocks, n_classes).to(device)\n",
    "x = torch.rand((16, 3, 32, 32))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331afd1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff782efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for x, y in tqdm(dataloader, \"Validation: \", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        prediction_logits = model(x)\n",
    "        loss += loss_fn(prediction_logits, y).item()\n",
    "        acc += (prediction_logits.argmax(1) == y).float().sum().item()\n",
    "    return loss / len(dataloader), acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1d23b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, validation_dataloader, loss_fn, optimizer, epochs, validation_freq, log):\n",
    "    losses, accs = [], []\n",
    "    for t in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_dataloader, f\"Epoch #{t}: \", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            prediction_logits = model(x)\n",
    "            loss = loss_fn(prediction_logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if t % validation_freq == 0:\n",
    "            lss, acc = validation(model, validation_dataloader, loss_fn)\n",
    "            print(f\"Loss = {lss}, Acc = {acc}\")\n",
    "            losses.append(lss)\n",
    "            accs.append(acc)\n",
    "            log_dict = {\"loss\": lss, \"accuracy\": acc}\n",
    "            if log:\n",
    "                wandb.log(log_dict)\n",
    "\n",
    "    return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3196e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1:   0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.7905403806808147, Acc = 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.834490197770139, Acc = 0.47533333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 2.0147361932916845, Acc = 0.48933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 2.3359557669213475, Acc = 0.47833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy\n\u001b[1;32m      2\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m training(model, dl_train, dl_val, loss_fn, optim, \u001b[39m50\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[63], line 11\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, train_dataloader, validation_dataloader, loss_fn, optimizer, epochs, validation_freq, log)\u001b[0m\n\u001b[1;32m      8\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(prediction_logits, y)\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39m%\u001b[39m validation_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = F.cross_entropy\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "training(model, dl_train, dl_val, loss_fn, optim, 50, 5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3878924-66ec-44bc-80af-4ce9b7e46ef2",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Measure your OOD detection performance\n",
    "\n",
    "There are several metrics used to evaluate OOD detection performance, we will concentrate on two threshold-free approaches: the area under the Receiver Operator Characteristic (ROC) curve for ID classification, and the area under the Precision-Recall curve for *both* ID and OOD scoring. See [the ODIN paper](https://arxiv.org/pdf/1706.02690.pdf) section 4.3 for a description of OOD metrics.\n",
    "\n",
    "Use the functions in `sklearn.metrics` to produce ROC and PR curves for your OOD detector. Some useful functions:\n",
    "\n",
    "+ [`sklearn.metric.RocCurveDisplay.from_predictions`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html)\n",
    "+ [`sklearn.metrics.PrecisionRecallDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95872246-85fb-41a5-8018-8643d76bfcb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e7265-77c4-4659-9bda-cc23247370bd",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2: Enhancing Robustness to Adversarial Attack\n",
    "\n",
    "In this second exercise we will experiment with enhancing our base model to be (more) robust to adversarial attacks. \n",
    "\n",
    "### Exercise 2.1: Implement FGSM and generate adversarial examples\n",
    "\n",
    "Recall that the Fast Gradient Sign Method (FGSM) perturbs samples in the direction of the gradient with respect to the input $\\mathbf{x}$:\n",
    "$$ \\boldsymbol{\\eta}(\\mathbf{x}) = \\varepsilon \\mathrm{sign}(\\nabla_{\\mathbf{x}} \\mathcal{L}(\\boldsymbol{\\theta}, \\mathbf{x}, y)) ) $$\n",
    "Implement FGSM and generate some *adversarial examples* using your trained ID model. Evaluate these samples qualitatively and quantitatively. Evaluate how dependent on $\\varepsilon$ the quality of these samples are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c052cbf-c45e-4d03-805e-53b917137043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82e7dc-cdfe-4201-8dc5-3891dfd6ea49",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Augment training with adversarial examples\n",
    "\n",
    "Use your implementation of FGSM to augment your training dataset with adversarial samples. Ideally, you should implement this data augmentation *on the fly* so that the adversarial samples are always generated using the current model. Evaluate whether the model is more (or less) robust to ID samples using your OOD detection pipeline and metrics you implemented in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da5e2d-30a9-48d6-86fd-6711612eb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8666b-85fc-4e83-b8d4-fe6a5dff0fea",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: Wildcard\n",
    "\n",
    "You know the drill. Pick *ONE* of the following exercises to complete.\n",
    "\n",
    "### Exercise 3.1: Implement ODIN for OOD detection\n",
    "ODIN is a very simple approach, and you can already start experimenting by implementing a temperature hyperparameter in your base model and doing a grid search on $T$ and $\\varepsilon$.\n",
    "\n",
    "### Exercise 3.2: Implement JARN\n",
    "In exercise 2.2 you already implemented Jacobian-regularized learning to make your model more robust to adversarial samples. Add a *discriminator* to your model to encourage the adversarial samples used for regularization to be more *salient*.\n",
    "\n",
    "See [the JARN paper](https://arxiv.org/abs/1912.10185) for more details.\n",
    "\n",
    "### Exercise 3.3: Experiment with *targeted* adversarial attacks\n",
    "Implement the targeted Fast Gradient Sign Method to generate adversarial samples that *imitate* samples from a specific class. Evaluate your adversarial samples qualitatively and quantitatively.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
